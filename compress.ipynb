{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qz0qSOyBxox3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from whiteGPT.utils.data.gpt_dataset import AkutagawaSampleDataset as Dataset\n",
        "import MeCab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzK7g9mTjIM8"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, context_size, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(context_size, d_model)\n",
        "        for pos in range(context_size):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos,i]   = math.sin(pos/(10000**((2*i)/d_model)))\n",
        "                pe[pos,i+1] = math.cos(pos/(10000**((2*i)/d_model)))\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.pe[:, :x.size(1)].detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOvsG1ozcoGg"
      },
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, q, k, v, mask):\n",
        "        a = torch.matmul(q, k.transpose(2, 3)) / (d_model ** 0.5)\n",
        "        if mask is not None:\n",
        "            a = a.masked_fill(mask == 0, float(\"-inf\"))\n",
        "        a = F.softmax(a, dim=-1)\n",
        "        a = self.dropout(a)\n",
        "        a = torch.matmul(a, v)\n",
        "        return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7-h_jDn5xtg"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.fc_q = nn.Linear(d_model, d_model)\n",
        "        self.fc_k = nn.Linear(d_model, d_model)\n",
        "        self.fc_v = nn.Linear(d_model, d_model)\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        N, S, H, D = q.size(0), q.size(1), n_head, d_model // n_head\n",
        "        q = self.fc_q(q).view(N, S, H, D).transpose(1, 2)\n",
        "        k = self.fc_k(k).view(N, S, H, D).transpose(1, 2)\n",
        "        v = self.fc_v(v).view(N, S, H, D).transpose(1, 2)\n",
        "        attn = self.attention(q, k, v, mask=mask)\n",
        "        attn = attn.transpose(1, 2).contiguous().view(N, S, -1)\n",
        "        attn = self.dropout(self.fc(attn))\n",
        "        return attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW3puAtb0n81"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_model * 4 )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(d_model * 4, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = self.dropout(self.fc2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZLmeeB200KO"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention()\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        q = self.norm_1(x)\n",
        "        x = self.attn(q, q, q, mask) + x # 残差結合\n",
        "        x = self.ff(self.norm_2(x)) + x # 残差結合\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H3MZSp4m3A7"
      },
      "outputs": [],
      "source": [
        "class GPT(nn.Module):\n",
        "    def __init__(self, context_size, d_model):\n",
        "        super(GPT, self).__init__()\n",
        "        self.context_size = context_size\n",
        "        self.d_model = d_model\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(context_size, d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.transformer_block = nn.ModuleList(\n",
        "            [TransformerBlock() for _ in range(n_block)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.fc = nn.Linear(d_model * context_size, vocab_size)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.token_embedding(x) + self.positional_encoding(x)\n",
        "        x = self.dropout(x)\n",
        "        for block in self.transformer_block:\n",
        "            x = block(x, mask)\n",
        "        x = self.norm(x)\n",
        "        x = x.view(-1, self.context_size * self.d_model)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoZkbRAMNTVK"
      },
      "outputs": [],
      "source": [
        "def create_attention_mask(s):\n",
        "    return (torch.triu(torch.ones((s, s)),1) == 0) * 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J4jwV910y_Ty"
      },
      "outputs": [],
      "source": [
        "context_size = 10 \n",
        "vocab_size = 10   \n",
        "d_model = 256 \n",
        "n_head = 1 \n",
        "n_block = 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCHKVE-1NzUC"
      },
      "outputs": [],
      "source": [
        "model = GPT(context_size, d_model)\n",
        "x = [1,1,1,1,1,1,1,1,1,1]\n",
        "x = torch.LongTensor([x])\n",
        "y = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfRZVCHlm6B9",
        "outputId": "6aa15ae6-8e9f-4457-f531-10d8dc68f190"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1089,  0.7643,  0.0663,  0.9351,  0.1751, -0.4679, -0.2348, -0.1751,\n",
              "         -0.4797, -0.1268]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28QJUkQjnC0M",
        "outputId": "4aa50526-59c9-4f63-a712-968ef02c0f67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Nm-6q3GaRK",
        "outputId": "d167ad59-f6a7-4fbe-ed10-202c5f8dd065"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ok.\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset()\n",
        "dataset.tagger = MeCab.Tagger(\"-Owakati\")\n",
        "model_path = '/content/whiteGPT/model/akutagawa/pre-trained.pkl' #@param{type:'string'}\n",
        "model = torch.load(model_path, map_location='cpu', weights_only=False)\n",
        "print('ok.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "P2JPIgIbQJUu",
        "outputId": "40fa120c-6514-4885-8c1f-2a164eee537b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "良平は一瞬間呆気にとられた。もうかれこれ暗くなる事、去年の暮母と岩村まで来たが、今日の途はその三四倍ある事、それを今からたった一人、歩いて帰らなければならない事、――そう云う事が一時にわかったのである。良平は殆ど泣きそうになった。が、泣いても仕方がないと思った。泣いている場合ではないとも思った。彼は若い二人の土工に、取って附けたような御時宜をすると、どんどん線路伝いに走り出した。良平は少時無我夢中に線路の側を走り続けた。その内に懐の菓子包みが、邪魔になる事に気がついたから、それを路側へ抛り出す次手に、板草履も其処へ脱ぎ捨ててしまった。すると薄い足袋の裏へじかに小石が食いこんだが、足だけは遙かに軽くなった。彼は左に海を感じながら、急な坂路を駈け登った。時時涙がこみ上げて来ると、自然に顔が歪んで来る。――それは無理に我慢しても、鼻だけは絶えずくうくう鳴った。竹藪の側を駈け抜けると、夕焼けのした日金山の空も、もう火照りが消えかかっていた。良平は、愈気が気でなかった。往きと返りと変るせいか、景色の違うのも不安だった。すると今度は着物までも、汗の濡れ通ったのが気になったから、やはり必死に駈け続けたなり、羽織を路側へ脱いで捨てた。蜜柑畑へ来る頃には、あたりは暗くなる一方だった。「命さえ助かれば――」良平はそう思いながら、辷ってもつまずいても走って行った。やっと遠い夕闇の中に、村外れの工事場が見えた時、良平は一思いに泣きたくなった。しかしその時もべそはかいたが、とうとう泣かずに駈け続けた。彼の村へはいって見ると、もう両側の家家には、電燈の光がさし合っていた。良平はその電燈の光に、頭から汗の湯気の立つのが、彼自身にもはっきりわかった。井戸端に水を汲んでいる女衆や、畑から帰って来る男衆は、良平が喘ぎ喘ぎ走るのを見"
          ]
        }
      ],
      "source": [
        "## 芥川龍之介モデルで生成\n",
        "n_token = 500\n",
        "sentence = '良平は一瞬間呆気にとられた。'\n",
        "dataset.sample(model, sentence, n=n_token, t=0.1, use_topk=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "DjVuE6HjfTJ0",
        "outputId": "0adcaa13-e9e8-4eb6-d6f8-4faadcecafec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "遺族？　じゃこの画を描いた人は死んでいるのですか。」「死んでいるのです。もっとも生きている中から、死んだようなものでしたが。」私の好奇心はいつか私の不快な感情より強くなっていた。「どうして？」「この画描きは余程前から気が違っていたのです。」「この画を描いた時もですか。」「勿論です。気違いででもなければ、誰がこんな色の画を描くものですか。それをあなたは傑作だと云って感心してお出でなさる。そこが大に面白いですね。」記者はまた得意そうに、声を挙げて笑った。彼は私が私の不明を恥じるだろうと予測していたのであろう。あるいは一歩進めて、鑑賞上における彼自身の優越を私に印象させようと思っていたのかも知れない。しかし彼の期待は二つとも無駄になった。彼の話を聞くと共に、ほとんど厳粛にも近い感情が私の全精神に云いようのない波動を与えたからである。私は悚然として再びこの沼地の画を凝視した。そうして再びこの小さなカンヴァスの中に、恐しい焦躁と不安とに虐まれている傷しい芸術家の姿を見出した。そうしてあらゆる優れた芸術品から受ける様に、この黄いろい沼地の草木からも恍惚たる悲壮の感激を受けた。実際同じ会場に懸かっている大小さまざまな画の中で、この一枚に拮抗し得るほど力強い画は、どこにも見出す事が出来なかったのである。「大へんに感心していますね。」こう云う言と共に肩を叩かれた私は、あたかも何かが心から振い落されたような気もちがして、卒然と後をふり返った。「どうです、これは。」相手は無頓着にこう云いながら、剃刀を当てたばかりの顋で、沼地の画をさし示した。流行の茶の背広を着た、恰幅の好い、消息通を以て自ら任じている、――新聞の美術記者である。私はこの記者から前にも一二度不快な印象を受けた覚えがあるので、不承不承に返事をした。「傑作です。」「傑作――ですか。これは面白い。」記者は腹を揺って笑った。その声に驚かされたのであろう。近くで画を見ていた二三人の見物が皆云い合せたようにこちらを見た。私はいよいよ不快になった。「これは面白い。元来この画はね、会員の画じゃないのです。が、何しろ当人が口癖のようにここへ出す出すと云っていたものですから、遺族が審査員へ頼んで、やっとこの隅へ懸ける事になったのです。」「遺族？じゃこの画を描いた人は死んでいるのですか。」「死んでいるのです。もっとも生きている中から、死んだようなものでしたが。」私の好奇心はいつか私の不快な感情より強くなっていた。「どうして？」「この画描きは余程前から気が違っていたのです。」「この画を描いた時もですか。」「勿論です。気違いででもなければ、誰がこんな色の画を描くものですか。それをあなたは傑作だと云って感心してお出でなさる。そこが大に面白いですね。」記者はまた得意そうに、声を挙げて笑った。彼は私が私の不明を恥じるだろうと予測していたのであろう。あるいは一歩進めて、鑑賞上における彼自身の優越を私に印象させようと思っていたのかも知れない。しかし彼の期待は二つとも無駄になった。彼の話を聞くと共に、ほとんど厳粛にも近い感情が私の全精神に云いようのない波動を与えたからである。私は悚然として再びこの沼地の画を凝視した。そうして再びこの小さなカンヴァスの中に、恐しい焦躁と不安とに虐まれている傷しい芸術家の姿を見出した。そうしてあらゆる優れた芸術品から受ける様に、この黄いろい沼地の草木からも恍惚たる悲壮の感激を受けた。実際同じ会場に懸かっている大小さまざまな画の中で、この一枚に拮抗し得るほど力強い画は、どこにも見"
          ]
        }
      ],
      "source": [
        "n_token = 1000\n",
        "sentence = '遺族？じゃこの画を描いた人は'\n",
        "dataset.sample(model, sentence, n=n_token, t=0.1, use_topk=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
